{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42533fbe-6599-4740-b404-a6c0b1b9feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pybaseball import statcast, cache\n",
    "#from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import math\n",
    "from pybaseball import statcast\n",
    "import scipy.stats as stats\n",
    "#from catboost import Pool\n",
    "#import optuna\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import sqlite3\n",
    "cache.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a2a955-4934-4d80-bc1d-971415364c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('savant_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeccb7d7-444c-482c-a748-e8ac1dd87271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(87.48719346049047)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['velocity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963e3768-642f-416d-819a-96c79a81e713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0019141906923948483)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's select the key features for the \"Stuff+\" model as discussed:\n",
    "# - 'pitch_type'\n",
    "# - 'pitch_percent'\n",
    "# - 'swing_miss_percent'\n",
    "# - 'arm_angle'\n",
    "# - 'xbadiff'\n",
    "# - 'xobp'\n",
    "# - 'xslg'\n",
    "# - 'pitcher_run_value_per_100'\n",
    "# - 'batter_run_value_per_100'\n",
    "\n",
    "# We will also select 'swing_miss_percent' as our initial target variable\n",
    "\n",
    "# Selecting the relevant features\n",
    "selected_columns = [\n",
    "    'pitch_type', 'pitch_percent', 'swing_miss_percent', 'arm_angle', \n",
    "    'xbadiff', 'xobp', 'xslg', 'pitcher_run_value_per_100', 'batter_run_value_per_100'\n",
    "]\n",
    "\n",
    "data = data.dropna(subset=selected_columns)\n",
    "\n",
    "# Extracting the features and target variable\n",
    "features = data[selected_columns]\n",
    "target = data['swing_miss_percent']\n",
    "\n",
    "# One-hot encoding the categorical 'pitch_type' column to handle it in the model\n",
    "features_encoded = pd.get_dummies(features, columns=['pitch_type'], drop_first=True)\n",
    "\n",
    "# Splitting the data into training and testing sets for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# We will now train an initial regression model. I'll start with a Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error for performance evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0460b437-6bb3-4ce8-a25c-7d48da6f933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted\n",
      "3116    31.7     31.700\n",
      "668     37.5     37.500\n",
      "1213    36.4     36.400\n",
      "478     55.0     55.045\n",
      "530     30.5     30.500\n",
      "...      ...        ...\n",
      "4197    22.4     22.400\n",
      "321     44.4     44.366\n",
      "3043     8.3      8.325\n",
      "888     40.0     39.999\n",
      "655     43.1     43.089\n",
      "\n",
      "[881 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e69d4dcc-8f45-44f8-879e-729e7448f1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata['SwingMiss_norm'] = (data['swing_miss_percent'] / data['swing_miss_percent'].mean()) * 100\\ndata['xwOBA_norm'] = ((data['xwoba'] / data['xwoba'].mean())) * 100 # Inverse\\ndata['RunExp_norm'] = ((data['run_exp'] / data['run_exp'].mean())) * 100  # Inverse\\n\\n# Assigning weights\\nw1, w2, w3 = .3, .2, .5\\n\\n# Calculating Stuff+\\ndata['Stuff+'] = (\\n    w1 * data['SwingMiss_norm'] +\\n    w2 * data['xwOBA_norm'] +\\n    w3 * data['RunExp_norm']\\n)\\n\\n# Display the first few rows of the Stuff+ calculation\\ndata[['swing_miss_percent', 'xobp', 'pitcher_run_value_per_100', 'Stuff+']].head()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data['SwingMiss_norm'] = (data['swing_miss_percent'] / data['swing_miss_percent'].mean()) * 100\n",
    "data['xwOBA_norm'] = ((data['xwoba'] / data['xwoba'].mean())) * 100 # Inverse\n",
    "data['RunExp_norm'] = ((data['run_exp'] / data['run_exp'].mean())) * 100  # Inverse\n",
    "\n",
    "# Assigning weights\n",
    "w1, w2, w3 = .3, .2, .5\n",
    "\n",
    "# Calculating Stuff+\n",
    "data['Stuff+'] = (\n",
    "    w1 * data['SwingMiss_norm'] +\n",
    "    w2 * data['xwOBA_norm'] +\n",
    "    w3 * data['RunExp_norm']\n",
    ")\n",
    "\n",
    "# Display the first few rows of the Stuff+ calculation\n",
    "data[['swing_miss_percent', 'xobp', 'pitcher_run_value_per_100', 'Stuff+']].head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5867ad-90b4-432f-83d9-4438bb8913fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.861\n",
      "0.32408764759309716\n",
      "-53.1\n",
      "79.3\n",
      "0.24831970935513178\n"
     ]
    }
   ],
   "source": [
    "print(data['xwoba'].min())\n",
    "print(data['xwoba'].max())\n",
    "print(data['xwoba'].mean())\n",
    "print(data['pitcher_run_exp'].min())\n",
    "print(data['pitcher_run_exp'].max())\n",
    "print(data['pitcher_run_exp'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622209cb-dc8b-47cf-9a4c-219750b1b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.34831970935513\n"
     ]
    }
   ],
   "source": [
    "# different normailzation so all are around 60-150, average at 100\n",
    "data['pre_new_all_+'] = data['pitcher_run_exp'] - data['pitcher_run_exp'].min()\n",
    "print(data['pre_new_all_+'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8c979a2b-8644-4ef7-85fd-967bc2807889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swing_miss_percent</th>\n",
       "      <th>xwoba</th>\n",
       "      <th>pitcher_run_exp</th>\n",
       "      <th>hardhit_percent</th>\n",
       "      <th>Stuff+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.9</td>\n",
       "      <td>0.225</td>\n",
       "      <td>72.7</td>\n",
       "      <td>32.053176</td>\n",
       "      <td>134.864968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>0.243</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.984544</td>\n",
       "      <td>127.835927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.7</td>\n",
       "      <td>0.107</td>\n",
       "      <td>14.5</td>\n",
       "      <td>26.785714</td>\n",
       "      <td>126.447414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.4</td>\n",
       "      <td>0.146</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>126.400194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.7</td>\n",
       "      <td>0.300</td>\n",
       "      <td>79.3</td>\n",
       "      <td>34.270650</td>\n",
       "      <td>126.163772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   swing_miss_percent  xwoba  pitcher_run_exp  hardhit_percent      Stuff+\n",
       "0                44.9  0.225             72.7        32.053176  134.864968\n",
       "1                39.5  0.243             60.0        29.984544  127.835927\n",
       "2                56.7  0.107             14.5        26.785714  126.447414\n",
       "3                58.4  0.146             19.0        23.076923  126.400194\n",
       "4                25.7  0.300             79.3        34.270650  126.163772"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('savant_data.csv')\n",
    "\n",
    "std_dev_pre = data['pitcher_run_exp'].std()\n",
    "std_dev_xwoba = data['xwoba'].std()\n",
    "std_dev_swm = data['swing_miss_percent'].std()\n",
    "#std_dev_hhr = data['hardhit_percent'].std()\n",
    "#std_dev_prve100 = data['pitcher_run_value_per_100'].std()\n",
    "\n",
    "# try with standard dev\n",
    "data['SwingMiss_norm'] = ((data['swing_miss_percent'] - data['swing_miss_percent'].mean()) / std_dev_swm) * 10\n",
    "data['xwOBA_norm'] = (((data['xwoba'].mean() - data['xwoba'])) / std_dev_xwoba) * 10\n",
    "data['RunExp_norm'] = ((data['pitcher_run_exp'] - data['pitcher_run_exp'].mean()) / std_dev_pre) * 10\n",
    "#data['HardHit_norm'] = ((data['hardhit_percent'].mean() - data['hardhit_percent']) / std_dev_hhr) * 10\n",
    "#data['prve100_norm'] = ((data['pitcher_run_value_per_100'] - data['pitcher_run_value_per_100'].mean()) / std_dev_prve100) * 50\n",
    "\n",
    "# Assigning weights\n",
    "w1, w2, w3 = 1/3, 1/3, 1/3\n",
    "\n",
    "# Calculating Stuff+\n",
    "data['Stuff+'] = (\n",
    "    w1 * data['SwingMiss_norm'] +\n",
    "    w2 * data['xwOBA_norm'] +\n",
    "    w3 * data['RunExp_norm']\n",
    ")\n",
    "#w4 * data['HardHit_norm']\n",
    "\n",
    "data['Stuff+'] = (data['Stuff+']) + 100\n",
    "\n",
    "# Display the first few rows of the Stuff+ calculation\n",
    "data[['swing_miss_percent', 'xwoba', 'pitcher_run_exp', 'hardhit_percent', 'Stuff+']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9d521279-ab1d-4d03-8099-93fc55e523f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "features_sorted = data.sort_values(by='Stuff+', ascending=False)\n",
    "print(data['Stuff+'].mean())\n",
    "features_sorted.to_csv('savant_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d4f4ab74-5bd2-4a19-b456-8336db326d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[data['pitches'] >= 200]\n",
    "filtered_data = filtered_data.sort_values(by='Stuff+', ascending=False)\n",
    "filtered_data.to_csv('STUFF+Initial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ed86fb57-03df-4f2b-8219-027e7323b191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pitches  player_id         player_name  total_pitches pitch_type  \\\n",
      "4      6224     669203      Burnes, Corbin          11943         FC   \n",
      "11     1278     621237      Alvarado, JosÃ©           3720         FC   \n",
      "16      318     596112  Stephenson, Robert           2444         FC   \n",
      "59     2802     661403     Clase, Emmanuel           4080         FC   \n",
      "88     1489     677651        Garcia, Luis           5435         FC   \n",
      "\n",
      "    pitch_percent     ba    iso  babip    slg  ...  z_diff  fastball_x_y  \\\n",
      "4            52.1  0.227  0.115  0.278  0.341  ...   -0.07          0.69   \n",
      "11           34.4  0.136  0.063  0.327  0.199  ...   -0.01          0.80   \n",
      "16           13.0  0.101  0.152  0.143  0.253  ...    0.21          1.15   \n",
      "59           68.7  0.212  0.071  0.259  0.283  ...   -0.02          0.69   \n",
      "88           27.4  0.167  0.119  0.237  0.286  ...    0.04          1.50   \n",
      "\n",
      "    fastball_z_y  fastball_x  fastball_z  HardHit_norm  veloXmovement  \\\n",
      "4           6.01        0.69        6.01      2.277585     -27.360162   \n",
      "11          6.62        0.80        6.62      0.789136      -3.860095   \n",
      "16          5.82        1.15        5.82      7.983605       1.553488   \n",
      "59          6.12        0.69        6.12      2.857567     -24.537960   \n",
      "88          6.18        1.50        6.18      6.288187     -17.278401   \n",
      "\n",
      "    vertXhoriz  veloXrelease  prve100_norm  \n",
      "4    -0.288002       613.700     18.307451  \n",
      "11   -0.041417       630.032     23.887861  \n",
      "16    0.017534       523.626     40.117851  \n",
      "59   -0.246365       648.396     21.867447  \n",
      "88   -0.201850       528.152     19.261374  \n",
      "\n",
      "[5 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data[filtered_data['pitch_type'] == 'FC'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "965b2c1f-b616-490b-b14b-f8e97f3e927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(38.86911871125941)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stuff Model!\n",
    "# First, let's select the key features for the \"Stuff+\" model as discussed:\n",
    "# - 'pitch_type'\n",
    "# - 'velocity'\n",
    "# - 'api_break_z_induced'\n",
    "# - 'api_break_x_arm'\n",
    "# - 'release_extension'\n",
    "# - 'spin_rate'\n",
    "# - 'release_pos_x'\n",
    "# - 'release_pos_z'\n",
    "# - 'x_diff'  \n",
    "# - 'z_diff'\n",
    "# - 'Stuff+'\n",
    "\n",
    "data = pd.read_csv('STUFF+Initial.csv')\n",
    "\n",
    "# Adding New Variables, interactions\n",
    "data['veloXspin'] = data['velocity'] * data['spin_rate']\n",
    "data['veloXmovement'] = data['velocity'] * data['api_break_z_induced'] * data['api_break_x_arm']\n",
    "data['vertXhoriz'] = data['api_break_z_induced'] * data['api_break_x_arm']\n",
    "data['veloXrelease'] = data['release_extension'] * data['velocity']\n",
    "\n",
    "# Selecting the relevant features\n",
    "selected_columns = [\n",
    "    'pitch_type', 'velocity', 'api_break_z_induced', 'api_break_x_arm', 'release_extension', 'spin_rate', 'release_pos_x_norm', 'release_pos_z', 'x_diff', 'z_diff', 'veloXrelease', 'veloXmovement' \n",
    "]\n",
    "\n",
    "data = data.dropna(subset=selected_columns)\n",
    "\n",
    "# Extracting the features and target variable\n",
    "features = data[selected_columns]\n",
    "target = data['Stuff+']\n",
    "\n",
    "# One-hot encoding the categorical 'pitch_type' column to handle it in the model\n",
    "features_encoded = pd.get_dummies(features, columns=['pitch_type'], drop_first=True)\n",
    "\n",
    "# Splitting the data into training and testing sets for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# We will now train an initial regression model. I'll start with a Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=2,\n",
    "                      min_samples_split=10, n_estimators=300, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error for performance evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "115266c7-7c23-4317-89bf-215cbd4bfcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['velocity', 'api_break_z_induced', 'api_break_x_arm',\n",
      "       'release_extension', 'spin_rate', 'release_pos_x_norm', 'release_pos_z',\n",
      "       'x_diff', 'z_diff', 'veloXrelease', 'veloXmovement', 'pitch_type_CU',\n",
      "       'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FO', 'pitch_type_FS',\n",
      "       'pitch_type_KC', 'pitch_type_KN', 'pitch_type_SC', 'pitch_type_SI',\n",
      "       'pitch_type_SL', 'pitch_type_ST', 'pitch_type_SV'],\n",
      "      dtype='object')\n",
      "          Actual   Predicted\n",
      "1587   98.483882  105.535016\n",
      "2203   93.911958   98.922799\n",
      "772   104.658229  102.781919\n",
      "1732   97.485941  103.792992\n",
      "387   108.734389  101.085303\n",
      "...          ...         ...\n",
      "1905   96.233090  103.854915\n",
      "252   110.997915  100.124339\n",
      "1793   96.985262  101.595304\n",
      "2332   92.833100   96.056152\n",
      "2103   94.695396  103.813364\n",
      "\n",
      "[573 rows x 2 columns]\n",
      "121.266536736447\n",
      "111.85211189810039\n",
      "99.9140551925534\n",
      "100.29518882277591\n",
      "80.63239245783055\n",
      "89.53508902240219\n"
     ]
    }
   ],
   "source": [
    "print(features_encoded.columns)\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "print(comparison)\n",
    "print(y_test.max())\n",
    "print(y_pred.max())\n",
    "print(y_test.mean())\n",
    "print(y_pred.mean())\n",
    "print(y_test.min())\n",
    "print(y_pred.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a9eb41a2-7465-4818-be40-de7717923b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(32.32139961824945)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pitch_data = [data['velocity'], data['api_break_z_induced'], data['api_break_x_arm'], data['release_extension'], data['spin_rate'], data['release_pos_x_norm'], data['release_pos_z'], data['x_diff'], data['z_diff'],  data['pitch_type_CU'], data['pitch_type_FC'], data['pitch_type_FF'], data['pitch_type_FO'], data['pitch_type_FS'], data['pitch_type_KC'], data['pitch_type_KN'], data['pitch_type_SC'], data['pitch_type_SI'], data['pitch_type_SL'], data['pitch_type_ST'], data['pitch_type_SV']]\n",
    "predictions = rf_model.predict(features_encoded)\n",
    "data['Stuff+_perdicted'] = predictions\n",
    "data['Stuff_diff'] = data['Stuff+'] - data['Stuff+_perdicted']\n",
    "data['NewStuff+_perdicted'] = ((data['Stuff+_perdicted'] - 100) * 2) + 100\n",
    "data['NewStuff_diff'] = data['Stuff+'] - data['NewStuff+_perdicted']\n",
    "filtered_data = data[data['pitches'] >= 200]\n",
    "filtered_data = filtered_data.sort_values(by='Stuff+', ascending=False)\n",
    "filtered_data.to_csv('STUFF+Initial.csv', index=False)\n",
    "mse = mean_squared_error(filtered_data['Stuff+'], filtered_data['NewStuff+_perdicted'])\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5d7a00c9-07d5-49ba-9452-77686820195e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 22 features, but RandomForestRegressor is expecting 23 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[251], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      5\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX does not have valid feature names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m a_fastball \u001b[38;5;241m=\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmy_fastball\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(a_fastball)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:1063\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1061\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 22 features, but RandomForestRegressor is expecting 23 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "my_fastball = [98, 1.4, 1.2, 6.5, 2300, 2.55, 6.02, 0, 0, False, False, False, True, False, False, False, False, False, False, False, False, False]\n",
    "#a_slider = rf_model.predict([my_slider], columns=features_encoded)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "a_fastball = rf_model.predict([my_fastball])\n",
    "print(a_fastball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a78b67ac-bb51-4dbc-bc82-ce4e9186adb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swing_miss_percent</th>\n",
       "      <th>ba</th>\n",
       "      <th>launch_speed</th>\n",
       "      <th>Unhittable+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.9</td>\n",
       "      <td>0.169</td>\n",
       "      <td>86.3</td>\n",
       "      <td>112.741857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>0.169</td>\n",
       "      <td>85.6</td>\n",
       "      <td>111.602048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.7</td>\n",
       "      <td>0.102</td>\n",
       "      <td>84.6</td>\n",
       "      <td>122.675825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.4</td>\n",
       "      <td>0.099</td>\n",
       "      <td>79.9</td>\n",
       "      <td>128.610712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.7</td>\n",
       "      <td>0.227</td>\n",
       "      <td>87.8</td>\n",
       "      <td>100.936010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   swing_miss_percent     ba  launch_speed  Unhittable+\n",
       "0                44.9  0.169          86.3   112.741857\n",
       "1                39.5  0.169          85.6   111.602048\n",
       "2                56.7  0.102          84.6   122.675825\n",
       "3                58.4  0.099          79.9   128.610712\n",
       "4                25.7  0.227          87.8   100.936010"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('savant_data.csv')\n",
    "\n",
    "std_dev_ba = data['ba'].std()\n",
    "std_dev_ls = data['launch_speed'].std()\n",
    "std_dev_swm = data['swing_miss_percent'].std()\n",
    "\n",
    "# try with standard dev\n",
    "data['SwingMiss_norm'] = ((data['swing_miss_percent'] - data['swing_miss_percent'].mean()) / std_dev_swm) * 10\n",
    "data['ls_norm'] = ((data['launch_speed'].mean() - data['launch_speed']) / std_dev_ls) * 10\n",
    "data['ba_norm'] = ((data['ba'].mean() - data['ba']) / std_dev_ba) * 10\n",
    "\n",
    "# Assigning weights\n",
    "w1, w2, w3 = 1/3, 1/3, 1/3\n",
    "\n",
    "# Calculating Unhittable+\n",
    "data['Unhittable+'] = (\n",
    "    w1 * data['SwingMiss_norm'] +\n",
    "    w2 * data['ls_norm'] +\n",
    "    w3 * data['ba_norm']\n",
    ")\n",
    "\n",
    "data['Unhittable+'] = (data['Unhittable+'] + 100)\n",
    "\n",
    "# Display the first few rows of the Stuff+ calculation\n",
    "data[['swing_miss_percent', 'ba', 'launch_speed', 'Unhittable+']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cd568397-bfd1-4142-b9df-37e71994f7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(100.0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_unhit = data[data['pitches'] >= 200]\n",
    "filtered_data_unhit = filtered_data_unhit.sort_values(by='Unhittable+', ascending=False)\n",
    "filtered_data_unhit.to_csv('Unhittable+Initial.csv', index=False)\n",
    "data['Unhittable+'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a63e3014-6273-40d0-b5c4-bb21a5eef732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata['release_pos_x_norm'] = data['release_pos_x']\\ndata['release_pos_x_norm'] = data['release_pos_x_norm'].apply(lambda x: -x if x < 0 else x)\\n\\n# Filter for fastballs\\nfastball_df = data[data['pitch_type'] == 'FF']\\n\\n# Group by pitcher and calculate average x_pos and z_pos for fastballs\\nfastball_positions = fastball_df.groupby('player_name')[['release_pos_x_norm', 'release_pos_z']].mean().reset_index()\\nfastball_positions.rename(columns={'release_pos_x_norm': 'fastball_x', 'release_pos_z': 'fastball_z'}, inplace=True)\\n\\n# Step 2: Merge fastball positions into the original dataset\\ndata = data.merge(fastball_positions, on='player_name', how='left')\\n\\n# Step 3: Calculate differences for x_pos and z_pos\\ndata['x_diff'] = data['release_pos_x_norm'] - data['fastball_x']\\ndata['z_diff'] = data['release_pos_z'] - data['fastball_z']\\n\\n# Step 4: Filter for non-fastball pitches\\nsecondary_pitches = data[data['pitch_type'] != 'FF']\\n\\n# Step 5: Keep only relevant columns for the result\\nresult = secondary_pitches[['player_name', 'pitch_type', 'x_diff', 'z_diff']]\\n\\n# Output the result\\nprint(result.head())\\n\""
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data['release_pos_x_norm'] = data['release_pos_x']\n",
    "data['release_pos_x_norm'] = data['release_pos_x_norm'].apply(lambda x: -x if x < 0 else x)\n",
    "\n",
    "# Filter for fastballs\n",
    "fastball_df = data[data['pitch_type'] == 'FF']\n",
    "\n",
    "# Group by pitcher and calculate average x_pos and z_pos for fastballs\n",
    "fastball_positions = fastball_df.groupby('player_name')[['release_pos_x_norm', 'release_pos_z']].mean().reset_index()\n",
    "fastball_positions.rename(columns={'release_pos_x_norm': 'fastball_x', 'release_pos_z': 'fastball_z'}, inplace=True)\n",
    "\n",
    "# Step 2: Merge fastball positions into the original dataset\n",
    "data = data.merge(fastball_positions, on='player_name', how='left')\n",
    "\n",
    "# Step 3: Calculate differences for x_pos and z_pos\n",
    "data['x_diff'] = data['release_pos_x_norm'] - data['fastball_x']\n",
    "data['z_diff'] = data['release_pos_z'] - data['fastball_z']\n",
    "\n",
    "# Step 4: Filter for non-fastball pitches\n",
    "secondary_pitches = data[data['pitch_type'] != 'FF']\n",
    "\n",
    "# Step 5: Keep only relevant columns for the result\n",
    "result = secondary_pitches[['player_name', 'pitch_type', 'x_diff', 'z_diff']]\n",
    "\n",
    "# Output the result\n",
    "print(result.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "83397958-ae4d-44e2-99ed-d2abfa67e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8892904578818597\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "print(data['release_pos_x_norm'].mean())\n",
    "print(data[data['player_name'] == 'Valdez, Framber']['release_pos_x_norm'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "04231f37-a312-43cf-b269-50fa0243fb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.model_selection import GridSearchCV\\n\\nparam_grid = {\\n    'n_estimators': [100, 200, 300],\\n    'max_depth': [10, 20, None],\\n    'min_samples_split': [2, 5, 10],\\n    'min_samples_leaf': [1, 2, 5],\\n    'max_features': ['sqrt', 'log2', None]\\n}\\n\\nrf_model = RandomForestRegressor(random_state=42)\\ngrid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\\ngrid_search.fit(X_train, y_train)\\n\\n# Best parameters and model\\nbest_params = grid_search.best_params_\\nbest_rf_model = grid_search.best_estimator_\\n\""
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ac353fb2-63f4-4725-b1f0-6cfc928dbe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, n_estimators=300, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(best_params)\n",
    "print(best_rf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5c1410ef-745b-42a9-8ff9-e17d936f5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 39.764355157753606\n"
     ]
    }
   ],
   "source": [
    "# Importing XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "data = pd.read_csv('STUFF+Initial.csv')\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBRegressor(\n",
    "    random_state=42,  # Ensure reproducibility\n",
    "    n_estimators=300,  # Number of trees (default: 100)\n",
    "    learning_rate=0.01,  # Step size shrinkage (default: 0.3)\n",
    "    max_depth=4,       # Maximum tree depth (default: 6)\n",
    "    objective='reg:squarederror'  # Regression objective\n",
    ")\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error for performance evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9134360f-831d-4428-9c89-1da600410192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.266536736447\n",
      "110.30937\n",
      "99.9140551925534\n",
      "100.25163\n",
      "80.63239245783055\n",
      "91.44656\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "print(y_test.max())\n",
    "print(y_pred.max())\n",
    "print(y_test.mean())\n",
    "print(y_pred.mean())\n",
    "print(y_test.min())\n",
    "print(y_pred.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dc58f251-9892-49c4-a04b-d48272ae8a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=300; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "best_xgb_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3b822a0f-469e-47a2-8a20-1dac93491128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pitches  player_id      player_name  total_pitches pitch_type  \\\n",
      "0     4861     656302     Cease, Dylan          12527         SL   \n",
      "1     4610     450203  Morton, Charlie          11523         CU   \n",
      "2      508     642585  Bautista, FÃ©lix           1983         FS   \n",
      "3      955     518585   Cruz, Fernando           2518         FS   \n",
      "4     6224     669203   Burnes, Corbin          11943         FC   \n",
      "\n",
      "   pitch_percent     ba    iso  babip    slg  ...  fastball_z  HardHit_norm  \\\n",
      "0           38.8  0.169  0.098  0.262  0.267  ...        6.32      3.743808   \n",
      "1           40.0  0.169  0.098  0.267  0.267  ...        5.50      5.111614   \n",
      "2           25.6  0.102  0.072  0.264  0.175  ...        6.99      7.226722   \n",
      "3           37.9  0.099  0.046  0.329  0.145  ...        5.95      9.679022   \n",
      "4           52.1  0.227  0.115  0.278  0.341  ...        6.01      2.277585   \n",
      "\n",
      "   veloXmovement  vertXhoriz  veloXrelease  prve100_norm  Stuff+_perdicted  \\\n",
      "0      -2.239677   -0.025773       536.173     20.258800        114.099438   \n",
      "1      75.233370    0.923109       501.225     18.555256        110.815981   \n",
      "2      31.832396    0.359688       578.790     32.288741        111.292534   \n",
      "3       9.673378    0.118692       558.275     24.568610        114.699797   \n",
      "4     -27.360162   -0.288002       613.700     18.307451        109.022899   \n",
      "\n",
      "   Stuff_diff  NewStuff+_perdicted  NewStuff_diff  \n",
      "0   20.765530           128.198876       6.666092  \n",
      "1   17.019945           121.631963       6.203964  \n",
      "2   15.154881           122.585068       3.862347  \n",
      "3   11.700397           129.399594      -2.999400  \n",
      "4   17.140873           118.045798       8.117974  \n",
      "\n",
      "[5 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c56a0-50b9-472e-87af-ddb2a6a65206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
