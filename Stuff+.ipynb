{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "42533fbe-6599-4740-b404-a6c0b1b9feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pybaseball import statcast, cache\n",
    "#from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import math\n",
    "from pybaseball import statcast\n",
    "import scipy.stats as stats\n",
    "#from catboost import Pool\n",
    "#import optuna\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import sqlite3\n",
    "cache.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "37a2a955-4934-4d80-bc1d-971415364c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('savant_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aeccb7d7-444c-482c-a748-e8ac1dd87271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(87.48719346049047)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['velocity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "963e3768-642f-416d-819a-96c79a81e713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0019104812712824825)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's select the key features for the \"Stuff+\" model as discussed:\n",
    "# - 'pitch_type'\n",
    "# - 'pitch_percent'\n",
    "# - 'swing_miss_percent'\n",
    "# - 'arm_angle'\n",
    "# - 'xbadiff'\n",
    "# - 'xobp'\n",
    "# - 'xslg'\n",
    "# - 'pitcher_run_value_per_100'\n",
    "# - 'batter_run_value_per_100'\n",
    "\n",
    "# We will also select 'swing_miss_percent' as our initial target variable\n",
    "\n",
    "# Selecting the relevant features\n",
    "selected_columns = [\n",
    "    'pitch_type', 'pitch_percent', 'swing_miss_percent', 'arm_angle', \n",
    "    'xbadiff', 'xobp', 'xslg', 'pitcher_run_value_per_100', 'batter_run_value_per_100'\n",
    "]\n",
    "\n",
    "data = data.dropna(subset=selected_columns)\n",
    "\n",
    "# Extracting the features and target variable\n",
    "features = data[selected_columns]\n",
    "target = data['swing_miss_percent']\n",
    "\n",
    "# One-hot encoding the categorical 'pitch_type' column to handle it in the model\n",
    "features_encoded = pd.get_dummies(features, columns=['pitch_type'], drop_first=True)\n",
    "\n",
    "# Splitting the data into training and testing sets for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# We will now train an initial regression model. I'll start with a Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error for performance evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0460b437-6bb3-4ce8-a25c-7d48da6f933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual  Predicted\n",
      "3116    31.7     31.700\n",
      "668     37.5     37.500\n",
      "1213    36.4     36.400\n",
      "478     55.0     55.038\n",
      "530     30.5     30.500\n",
      "...      ...        ...\n",
      "4197    22.4     22.400\n",
      "321     44.4     44.366\n",
      "3043     8.3      8.325\n",
      "888     40.0     39.998\n",
      "655     43.1     43.089\n",
      "\n",
      "[881 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e69d4dcc-8f45-44f8-879e-729e7448f1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata['SwingMiss_norm'] = (data['swing_miss_percent'] / data['swing_miss_percent'].mean()) * 100\\ndata['xwOBA_norm'] = ((data['xwoba'] / data['xwoba'].mean())) * 100 # Inverse\\ndata['RunExp_norm'] = ((data['run_exp'] / data['run_exp'].mean())) * 100  # Inverse\\n\\n# Assigning weights\\nw1, w2, w3 = .3, .2, .5\\n\\n# Calculating Stuff+\\ndata['Stuff+'] = (\\n    w1 * data['SwingMiss_norm'] +\\n    w2 * data['xwOBA_norm'] +\\n    w3 * data['RunExp_norm']\\n)\\n\\n# Display the first few rows of the Stuff+ calculation\\ndata[['swing_miss_percent', 'xobp', 'pitcher_run_value_per_100', 'Stuff+']].head()\\n\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data['SwingMiss_norm'] = (data['swing_miss_percent'] / data['swing_miss_percent'].mean()) * 100\n",
    "data['xwOBA_norm'] = ((data['xwoba'] / data['xwoba'].mean())) * 100 # Inverse\n",
    "data['RunExp_norm'] = ((data['run_exp'] / data['run_exp'].mean())) * 100  # Inverse\n",
    "\n",
    "# Assigning weights\n",
    "w1, w2, w3 = .3, .2, .5\n",
    "\n",
    "# Calculating Stuff+\n",
    "data['Stuff+'] = (\n",
    "    w1 * data['SwingMiss_norm'] +\n",
    "    w2 * data['xwOBA_norm'] +\n",
    "    w3 * data['RunExp_norm']\n",
    ")\n",
    "\n",
    "# Display the first few rows of the Stuff+ calculation\n",
    "data[['swing_miss_percent', 'xobp', 'pitcher_run_value_per_100', 'Stuff+']].head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7e5867ad-90b4-432f-83d9-4438bb8913fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.861\n",
      "0.32408764759309716\n",
      "-53.1\n",
      "79.3\n",
      "0.24831970935513178\n"
     ]
    }
   ],
   "source": [
    "print(data['xwoba'].min())\n",
    "print(data['xwoba'].max())\n",
    "print(data['xwoba'].mean())\n",
    "print(data['pitcher_run_exp'].min())\n",
    "print(data['pitcher_run_exp'].max())\n",
    "print(data['pitcher_run_exp'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "622209cb-dc8b-47cf-9a4c-219750b1b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.34831970935513\n"
     ]
    }
   ],
   "source": [
    "# different normailzation so all are around 60-150, average at 100\n",
    "data['pre_new_all_+'] = data['pitcher_run_exp'] - data['pitcher_run_exp'].min()\n",
    "print(data['pre_new_all_+'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8c979a2b-8644-4ef7-85fd-967bc2807889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swing_miss_percent</th>\n",
       "      <th>xwoba</th>\n",
       "      <th>pitcher_run_exp</th>\n",
       "      <th>hardhit_percent</th>\n",
       "      <th>Stuff+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.9</td>\n",
       "      <td>0.225</td>\n",
       "      <td>72.7</td>\n",
       "      <td>32.053176</td>\n",
       "      <td>149.233965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.7</td>\n",
       "      <td>0.300</td>\n",
       "      <td>79.3</td>\n",
       "      <td>34.270650</td>\n",
       "      <td>147.819264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.5</td>\n",
       "      <td>0.243</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.984544</td>\n",
       "      <td>140.235947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.299</td>\n",
       "      <td>61.8</td>\n",
       "      <td>46.261090</td>\n",
       "      <td>137.466268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.9</td>\n",
       "      <td>0.280</td>\n",
       "      <td>57.5</td>\n",
       "      <td>40.870787</td>\n",
       "      <td>135.902519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   swing_miss_percent  xwoba  pitcher_run_exp  hardhit_percent      Stuff+\n",
       "0                44.9  0.225             72.7        32.053176  149.233965\n",
       "1                25.7  0.300             79.3        34.270650  147.819264\n",
       "2                39.5  0.243             60.0        29.984544  140.235947\n",
       "3                26.0  0.299             61.8        46.261090  137.466268\n",
       "4                28.9  0.280             57.5        40.870787  135.902519"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_dev_pre = data['pitcher_run_exp'].std()\n",
    "std_dev_xwoba = data['xwoba'].std()\n",
    "std_dev_swm = data['swing_miss_percent'].std()\n",
    "std_dev_hhr = data['hardhit_percent'].std()\n",
    "\n",
    "# try with standard dev\n",
    "data['SwingMiss_norm'] = ((data['swing_miss_percent'] - data['swing_miss_percent'].mean()) / std_dev_swm) * 10\n",
    "data['xwOBA_norm'] = (((data['xwoba'].mean() - data['xwoba'])) / std_dev_xwoba) * 10\n",
    "data['RunExp_norm'] = ((data['pitcher_run_exp'] - data['pitcher_run_exp'].mean()) / std_dev_pre) * 10\n",
    "#data['HardHit_norm'] = ((data['hardhit_percent'].mean() - data['hardhit_percent']) / std_dev_hhr) * 10\n",
    "\n",
    "# Assigning weights\n",
    "w1, w2, w3 = .2, .3, .5\n",
    "\n",
    "# Calculating Stuff+\n",
    "data['Stuff+'] = (\n",
    "    w1 * data['SwingMiss_norm'] +\n",
    "    w2 * data['xwOBA_norm'] +\n",
    "    w3 * data['RunExp_norm']\n",
    ")\n",
    "#w4 * data['HardHit_norm']\n",
    "\n",
    "data['Stuff+'] = (data['Stuff+'] + 100)\n",
    "\n",
    "# Display the first few rows of the Stuff+ calculation\n",
    "data[['swing_miss_percent', 'xwoba', 'pitcher_run_exp', 'hardhit_percent', 'Stuff+']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9d521279-ab1d-4d03-8099-93fc55e523f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "features_sorted = data.sort_values(by='Stuff+', ascending=False)\n",
    "print(data['Stuff+'].mean())\n",
    "features_sorted.to_csv('savant_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d4f4ab74-5bd2-4a19-b456-8336db326d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[data['pitches'] >= 200]\n",
    "filtered_data = filtered_data.sort_values(by='Stuff+', ascending=False)\n",
    "filtered_data.to_csv('STUFF+Initial.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ed86fb57-03df-4f2b-8219-027e7323b191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pitches  player_id         player_name  total_pitches pitch_type  \\\n",
      "1      6224     669203      Burnes, Corbin          11943         FC   \n",
      "13     2802     661403     Clase, Emmanuel           4080         FC   \n",
      "29     1278     621237      Alvarado, Jos√©           3720         FC   \n",
      "49     2652     650644       Civale, Aaron           8204         FC   \n",
      "82      318     596112  Stephenson, Robert           2444         FC   \n",
      "\n",
      "    pitch_percent     ba    iso  babip    slg  ...  release_pos_x_norm  \\\n",
      "1            52.1  0.227  0.115  0.278  0.341  ...                0.77   \n",
      "13           68.7  0.212  0.071  0.259  0.283  ...                0.71   \n",
      "29           34.4  0.136  0.063  0.327  0.199  ...                1.11   \n",
      "49           32.3  0.242  0.160  0.269  0.403  ...                0.72   \n",
      "82           13.0  0.101  0.152  0.143  0.253  ...                0.98   \n",
      "\n",
      "    fastball_x_x  fastball_z_x  x_diff  z_diff  fastball_x_y  fastball_z_y  \\\n",
      "1           0.69          6.01    0.08   -0.07          0.69          6.01   \n",
      "13          0.69          6.12    0.02   -0.02          0.69          6.12   \n",
      "29          0.80          6.62    0.31   -0.01          0.80          6.62   \n",
      "49          0.70          6.29    0.02    0.06          0.70          6.29   \n",
      "82          1.15          5.82   -0.17    0.21          1.15          5.82   \n",
      "\n",
      "    fastball_x  fastball_z  HardHit_norm  \n",
      "1         0.69        6.01      2.277585  \n",
      "13        0.69        6.12      2.857567  \n",
      "29        0.80        6.62      0.789136  \n",
      "49        0.70        6.29     -1.134435  \n",
      "82        1.15        5.82      7.983605  \n",
      "\n",
      "[5 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data[filtered_data['pitch_type'] == 'FC'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a78b67ac-bb51-4dbc-bc82-ce4e9186adb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swing_miss_percent</th>\n",
       "      <th>ba</th>\n",
       "      <th>launch_speed</th>\n",
       "      <th>Unhittable+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.9</td>\n",
       "      <td>0.169</td>\n",
       "      <td>86.3</td>\n",
       "      <td>109.318822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.7</td>\n",
       "      <td>0.227</td>\n",
       "      <td>87.8</td>\n",
       "      <td>100.988152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.5</td>\n",
       "      <td>0.169</td>\n",
       "      <td>85.6</td>\n",
       "      <td>108.188003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.211</td>\n",
       "      <td>91.3</td>\n",
       "      <td>98.992823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.9</td>\n",
       "      <td>0.211</td>\n",
       "      <td>89.0</td>\n",
       "      <td>101.504980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   swing_miss_percent     ba  launch_speed  Unhittable+\n",
       "0                44.9  0.169          86.3   109.318822\n",
       "1                25.7  0.227          87.8   100.988152\n",
       "2                39.5  0.169          85.6   108.188003\n",
       "3                26.0  0.211          91.3    98.992823\n",
       "4                28.9  0.211          89.0   101.504980"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_dev_ba = data['ba'].std()\n",
    "std_dev_ls = data['launch_speed'].std()\n",
    "std_dev_swm = data['swing_miss_percent'].std()\n",
    "\n",
    "# try with standard dev\n",
    "data['SwingMiss_norm'] = ((data['swing_miss_percent'] - data['swing_miss_percent'].mean()) / std_dev_swm) * 10\n",
    "data['ls_norm'] = ((data['launch_speed'].mean() - data['launch_speed']) / std_dev_ls) * 10\n",
    "data['ba_norm'] = ((data['ba'].mean() - data['ba']) / std_dev_ba) * 10\n",
    "\n",
    "# Assigning weights\n",
    "w1, w2, w3 = 1/3, 1/3, 1/3\n",
    "\n",
    "# Calculating Unhittable+\n",
    "data['Unhittable+'] = (\n",
    "    w1 * data['SwingMiss_norm'] +\n",
    "    w2 * data['ls_norm'] +\n",
    "    w3 * data['ba_norm']\n",
    ")\n",
    "\n",
    "data['Unhittable+'] = (data['Unhittable+'] + 100)\n",
    "\n",
    "# Display the first few rows of the Stuff+ calculation\n",
    "data[['swing_miss_percent', 'ba', 'launch_speed', 'Unhittable+']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cd568397-bfd1-4142-b9df-37e71994f7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(100.0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_unhit = data[data['pitches'] >= 200]\n",
    "filtered_data_unhit = filtered_data_unhit.sort_values(by='Unhittable+', ascending=False)\n",
    "filtered_data_unhit.to_csv('Unhittable+Initial.csv', index=False)\n",
    "data['Unhittable+'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a63e3014-6273-40d0-b5c4-bb21a5eef732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata['release_pos_x_norm'] = data['release_pos_x']\\ndata['release_pos_x_norm'] = data['release_pos_x_norm'].apply(lambda x: -x if x < 0 else x)\\n\\n# Filter for fastballs\\nfastball_df = data[data['pitch_type'] == 'FF']\\n\\n# Group by pitcher and calculate average x_pos and z_pos for fastballs\\nfastball_positions = fastball_df.groupby('player_name')[['release_pos_x_norm', 'release_pos_z']].mean().reset_index()\\nfastball_positions.rename(columns={'release_pos_x_norm': 'fastball_x', 'release_pos_z': 'fastball_z'}, inplace=True)\\n\\n# Step 2: Merge fastball positions into the original dataset\\ndata = data.merge(fastball_positions, on='player_name', how='left')\\n\\n# Step 3: Calculate differences for x_pos and z_pos\\ndata['x_diff'] = data['release_pos_x_norm'] - data['fastball_x']\\ndata['z_diff'] = data['release_pos_z'] - data['fastball_z']\\n\\n# Step 4: Filter for non-fastball pitches\\nsecondary_pitches = data[data['pitch_type'] != 'FF']\\n\\n# Step 5: Keep only relevant columns for the result\\nresult = secondary_pitches[['player_name', 'pitch_type', 'x_diff', 'z_diff']]\\n\\n# Output the result\\nprint(result.head())\\n\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data['release_pos_x_norm'] = data['release_pos_x']\n",
    "data['release_pos_x_norm'] = data['release_pos_x_norm'].apply(lambda x: -x if x < 0 else x)\n",
    "\n",
    "# Filter for fastballs\n",
    "fastball_df = data[data['pitch_type'] == 'FF']\n",
    "\n",
    "# Group by pitcher and calculate average x_pos and z_pos for fastballs\n",
    "fastball_positions = fastball_df.groupby('player_name')[['release_pos_x_norm', 'release_pos_z']].mean().reset_index()\n",
    "fastball_positions.rename(columns={'release_pos_x_norm': 'fastball_x', 'release_pos_z': 'fastball_z'}, inplace=True)\n",
    "\n",
    "# Step 2: Merge fastball positions into the original dataset\n",
    "data = data.merge(fastball_positions, on='player_name', how='left')\n",
    "\n",
    "# Step 3: Calculate differences for x_pos and z_pos\n",
    "data['x_diff'] = data['release_pos_x_norm'] - data['fastball_x']\n",
    "data['z_diff'] = data['release_pos_z'] - data['fastball_z']\n",
    "\n",
    "# Step 4: Filter for non-fastball pitches\n",
    "secondary_pitches = data[data['pitch_type'] != 'FF']\n",
    "\n",
    "# Step 5: Keep only relevant columns for the result\n",
    "result = secondary_pitches[['player_name', 'pitch_type', 'x_diff', 'z_diff']]\n",
    "\n",
    "# Output the result\n",
    "print(result.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "83397958-ae4d-44e2-99ed-d2abfa67e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9051907356948228\n",
      "0.8633333333333333\n"
     ]
    }
   ],
   "source": [
    "print(data['release_pos_x_norm'].mean())\n",
    "print(data[data['player_name'] == 'Valdez, Framber']['release_pos_x_norm'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "965b2c1f-b616-490b-b14b-f8e97f3e927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(47.123149247893814)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stuff Model!\n",
    "# First, let's select the key features for the \"Stuff+\" model as discussed:\n",
    "# - 'pitch_type'\n",
    "# - 'velocity'\n",
    "# - 'api_break_z_induced'\n",
    "# - 'api_break_x_arm'\n",
    "# - 'release_extension'\n",
    "# - 'spin_rate'\n",
    "# - 'release_pos_x'\n",
    "# - 'release_pos_z'\n",
    "# - 'x_diff'  \n",
    "# - 'z_diff'\n",
    "# - 'Stuff+'\n",
    "\n",
    "# Adding New Variables, interactions\n",
    "#data['veloXspin'] = data['velocity'] * data['spin_rate']\n",
    "data['veloXmovement'] = data['velocity'] * data['api_break_z_induced'] * data['api_break_x_arm']\n",
    "data['vertXhoriz'] = data['api_break_z_induced'] * data['api_break_x_arm']\n",
    "data['veloXrelease'] = data['release_extension'] * data['velocity']\n",
    "\n",
    "\n",
    "# Selecting the relevant features\n",
    "selected_columns = [\n",
    "    'pitch_type', 'velocity', 'api_break_z_induced', 'api_break_x_arm', 'release_extension', 'spin_rate', 'release_pos_x_norm', 'release_pos_z', 'x_diff', 'z_diff', 'veloXmovement', 'vertXhoriz', 'veloXrelease'  \n",
    "]\n",
    "\n",
    "data = data.dropna(subset=selected_columns)\n",
    "\n",
    "# Extracting the features and target variable\n",
    "features = data[selected_columns]\n",
    "target = data['Stuff+']\n",
    "\n",
    "# One-hot encoding the categorical 'pitch_type' column to handle it in the model\n",
    "features_encoded = pd.get_dummies(features, columns=['pitch_type'], drop_first=True)\n",
    "\n",
    "# Splitting the data into training and testing sets for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# We will now train an initial regression model. I'll start with a Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(max_features='log2', min_samples_leaf=5, n_estimators=300,\n",
    "                      random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error for performance evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "04231f37-a312-43cf-b269-50fa0243fb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.model_selection import GridSearchCV\\n\\nparam_grid = {\\n    'n_estimators': [100, 200, 300],\\n    'max_depth': [10, 20, None],\\n    'min_samples_split': [2, 5, 10],\\n    'min_samples_leaf': [1, 2, 5],\\n    'max_features': ['sqrt', 'log2', None]\\n}\\n\\nrf_model = RandomForestRegressor(random_state=42)\\ngrid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\\ngrid_search.fit(X_train, y_train)\\n\\n# Best parameters and model\\nbest_params = grid_search.best_params_\\nbest_rf_model = grid_search.best_estimator_\\n\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ac353fb2-63f4-4725-b1f0-6cfc928dbe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n",
      "RandomForestRegressor(max_features='log2', min_samples_leaf=5, n_estimators=300,\n",
      "                      random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(best_params)\n",
    "print(best_rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "115266c7-7c23-4317-89bf-215cbd4bfcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Actual   Predicted\n",
      "3116   96.566818  105.277116\n",
      "668   106.215305   99.732955\n",
      "1213  103.372693   99.523464\n",
      "478   107.736617  105.532179\n",
      "530   107.245183   98.811478\n",
      "...          ...         ...\n",
      "4197   89.033675  100.482818\n",
      "321   109.885402  103.316115\n",
      "3043   96.852562   96.018759\n",
      "888   104.933370   96.030351\n",
      "655   106.336510   99.241483\n",
      "\n",
      "[881 rows x 2 columns]\n",
      "131.2395773932468\n",
      "106.34354741531877\n",
      "100.30638380203315\n",
      "99.91107125446334\n",
      "55.34589113982354\n",
      "94.09581186473645\n",
      "[112.13945392]\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "print(comparison)\n",
    "print(y_test.max())\n",
    "print(y_pred.max())\n",
    "print(y_test.mean())\n",
    "print(y_pred.mean())\n",
    "print(y_test.min())\n",
    "print(y_pred.min())\n",
    "cease_sl = [86.9, 0.08456, -0.30479, 6.17, 2817.0, 1.55, 6.12, 0.20999999999999996, -0.20000000000000018, -2.23967738456, -0.025773042399999998, 536.173, False, False, False, False, False, False, False, False, False, False, True, False, False]\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "a_slider = rf_model.predict([cease_sl])\n",
    "print(a_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "da38b149-f74a-4bea-9e97-71aaf9f4d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103.16249769]\n"
     ]
    }
   ],
   "source": [
    "my_slider = [82, -.08333, -.91667, 6.5, 2800, 2.55, 6.02, 0, 0, 6.26, .07635, 533, False, False, False, False, False, False, False, False, False, False, True, False, False]\n",
    "#a_slider = rf_model.predict([my_slider], columns=features_encoded)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "a_slider = rf_model.predict([my_slider])\n",
    "print(a_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d7a00c9-07d5-49ba-9452-77686820195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99.18038857]\n"
     ]
    }
   ],
   "source": [
    "my_fastball = [92, 1.4, 1.2, 6.5, 2300, 2.55, 6.02, 0, 0, 154.56, 1.68, , False, False, False, True, False, False, False, False, False, False, False, False, False]\n",
    "#a_slider = rf_model.predict([my_slider], columns=features_encoded)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "a_fastball = rf_model.predict([my_fastball])\n",
    "print(a_fastball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5c1410ef-745b-42a9-8ff9-e17d936f5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 47.970722678799085\n"
     ]
    }
   ],
   "source": [
    "# Importing XGBoost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBRegressor(\n",
    "    random_state=42,  # Ensure reproducibility\n",
    "    n_estimators=300,  # Number of trees (default: 100)\n",
    "    learning_rate=0.01,  # Step size shrinkage (default: 0.3)\n",
    "    max_depth=4,       # Maximum tree depth (default: 6)\n",
    "    objective='reg:squarederror'  # Regression objective\n",
    ")\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error for performance evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9134360f-831d-4428-9c89-1da600410192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.2395773932468\n",
      "111.34204\n",
      "100.30638380203315\n",
      "99.92812\n",
      "55.34589113982354\n",
      "93.4399\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "print(y_test.max())\n",
    "print(y_pred.max())\n",
    "print(y_test.mean())\n",
    "print(y_pred.mean())\n",
    "print(y_test.min())\n",
    "print(y_pred.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dc58f251-9892-49c4-a04b-d48272ae8a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=300; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=200; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=300; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.2, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "best_xgb_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3b822a0f-469e-47a2-8a20-1dac93491128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pitches  player_id      player_name  total_pitches pitch_type  \\\n",
      "0     4861     656302     Cease, Dylan          12527         SL   \n",
      "1     6224     669203   Burnes, Corbin          11943         FC   \n",
      "2     4610     450203  Morton, Charlie          11523         CU   \n",
      "3     5534     543037     Cole, Gerrit          11058         FF   \n",
      "4     5026     554430    Wheeler, Zack          11852         FF   \n",
      "\n",
      "   pitch_percent     ba    iso  babip    slg  ...  z_diff  fastball_x_y  \\\n",
      "0           38.8  0.169  0.098  0.262  0.267  ...   -0.20          1.34   \n",
      "1           52.1  0.227  0.115  0.278  0.341  ...   -0.07          0.69   \n",
      "2           40.0  0.169  0.098  0.267  0.267  ...   -0.10          2.27   \n",
      "3           50.0  0.211  0.168  0.277  0.379  ...    0.00          1.94   \n",
      "4           42.4  0.211  0.137  0.288  0.348  ...    0.00          1.81   \n",
      "\n",
      "   fastball_z_y  fastball_x  fastball_z  HardHit_norm  veloXspin  \\\n",
      "0          6.32        1.34        6.32      3.743808   244797.3   \n",
      "1          6.01        0.69        6.01      2.277585   255455.0   \n",
      "2          5.50        2.27        5.50      5.111614   250531.0   \n",
      "3          5.84        1.94        5.84     -5.650648   235321.2   \n",
      "4          5.48        1.81        5.48     -2.086510   233426.9   \n",
      "\n",
      "   veloXmovement  vertXhoriz  veloXrelease  \n",
      "0      -2.239677   -0.025773       536.173  \n",
      "1     -27.360162   -0.288002       613.700  \n",
      "2      75.233370    0.923109       501.225  \n",
      "3     116.831046    1.201965       624.024  \n",
      "4      83.454748    0.868416       695.764  \n",
      "\n",
      "[5 rows x 93 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c56a0-50b9-472e-87af-ddb2a6a65206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
